{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librer√≠as\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 genre  loudness    tempo  time_signature  key  mode  \\\n",
      "48942   jazz and blues   -18.996   89.147               1    0     1   \n",
      "48943   jazz and blues   -19.347  125.825               4    2     1   \n",
      "48944   jazz and blues    -9.472  121.707               4    2     1   \n",
      "48945   jazz and blues   -14.406   83.012               5    0     1   \n",
      "48946   jazz and blues    -9.289   76.013               4    7     0   \n",
      "48947   jazz and blues   -10.003  143.751               4    0     0   \n",
      "48948   jazz and blues   -11.161  122.412               4    0     1   \n",
      "48949   jazz and blues   -12.785  244.366               4   10     1   \n",
      "48950   jazz and blues    -5.834  143.886               1    9     0   \n",
      "48951   jazz and blues   -12.174   74.642               1    2     0   \n",
      "48952   jazz and blues    -7.535  139.480               3   11     1   \n",
      "48953   jazz and blues   -11.945  101.866               7    0     1   \n",
      "48954   jazz and blues   -11.294  122.794               4    7     0   \n",
      "48955   jazz and blues   -28.219   62.757               1   10     1   \n",
      "48956   jazz and blues   -31.245   49.871               1   10     1   \n",
      "48957   jazz and blues   -32.175   53.921               3   10     0   \n",
      "48958   jazz and blues   -33.101  117.646               1    4     1   \n",
      "48959   jazz and blues   -39.239   50.551               1    8     0   \n",
      "48960   jazz and blues   -36.548   48.258               1    0     0   \n",
      "48961   jazz and blues   -27.986  103.920               1    5     1   \n",
      "48962   jazz and blues   -29.408   29.310               4    1     1   \n",
      "48963   jazz and blues   -24.951   36.494               4   10     1   \n",
      "48964   jazz and blues   -25.821   67.582               5    7     0   \n",
      "48965   jazz and blues   -32.760   63.607               5   10     1   \n",
      "48966   jazz and blues   -24.658   65.904               1    5     1   \n",
      "48967   jazz and blues   -25.788  162.464               4    3     1   \n",
      "48968   jazz and blues   -27.912  121.598               1    1     1   \n",
      "48969   jazz and blues    -4.692  125.013               4    1     1   \n",
      "48970   jazz and blues    -4.477  125.019               4    1     1   \n",
      "48971   jazz and blues    -6.338  122.987               4    2     1   \n",
      "...                ...       ...      ...             ...  ...   ...   \n",
      "59570  soul and reggae    -6.924  240.368               7    6     0   \n",
      "59571  soul and reggae    -7.903  140.055               4   11     0   \n",
      "59572  soul and reggae   -15.444   39.300               4    1     0   \n",
      "59573  soul and reggae    -8.712  138.334               4    2     0   \n",
      "59574  soul and reggae    -8.848  159.715               5    8     1   \n",
      "59575  soul and reggae    -9.760  108.247               4    1     1   \n",
      "59576  soul and reggae   -16.202  165.054               4    2     1   \n",
      "59577  soul and reggae   -10.893  100.206               4   11     0   \n",
      "59578  soul and reggae    -8.537  153.644               4    2     1   \n",
      "59579  soul and reggae   -10.099   73.384               4    1     1   \n",
      "59580  soul and reggae   -12.117  136.330               4    2     1   \n",
      "59581  soul and reggae   -10.167  151.059               5    5     0   \n",
      "59582  soul and reggae   -13.869   63.805               3    8     1   \n",
      "59583  soul and reggae    -8.445  112.459               5    1     1   \n",
      "59584  soul and reggae    -7.476  143.590               4    1     1   \n",
      "59585  soul and reggae    -9.568  190.241               7   11     0   \n",
      "59586  soul and reggae    -9.115  123.739               5    4     0   \n",
      "59587  soul and reggae    -8.008   67.924               4    1     0   \n",
      "59588  soul and reggae    -6.245  106.960               7    7     0   \n",
      "59589  soul and reggae   -10.554  135.004               1    7     1   \n",
      "59590  soul and reggae   -13.278   98.959               1    9     1   \n",
      "59591  soul and reggae    -8.052   91.836               4   11     1   \n",
      "59592  soul and reggae    -7.960  111.986               5    8     0   \n",
      "59593  soul and reggae    -7.305  163.667               4    0     0   \n",
      "59594  soul and reggae    -8.656   91.837               3    5     0   \n",
      "59595  soul and reggae   -10.162   88.951               4   11     1   \n",
      "59596  soul and reggae    -5.466  130.615               3    9     1   \n",
      "59597  soul and reggae    -9.494   88.976               4    3     1   \n",
      "59598  soul and reggae    -7.617   67.929               3    0     1   \n",
      "59599  soul and reggae   -11.774   85.176               3    7     1   \n",
      "\n",
      "        duration  avg_timbre1  avg_timbre2  avg_timbre3  ...  var_timbre3  \\\n",
      "48942  256.86159    34.738162   -50.948828    20.177101  ...  1649.321047   \n",
      "48943  301.87057    34.033346   -39.733083    30.640298  ...  1670.689893   \n",
      "48944  158.85016    41.794197   -22.133118     3.518487  ...  2640.398239   \n",
      "48945  181.26322    38.637530   -64.807191   -21.920418  ...  1187.644248   \n",
      "48946  248.89424    43.089845   -27.351674    14.205832  ...  1164.272074   \n",
      "48947  151.19628    41.494052   -16.889975   -24.228268  ...  1847.627564   \n",
      "48948  166.21669    40.886150    -5.595101   -42.018501  ...  1401.094181   \n",
      "48949  245.44608    40.107366    -4.388319   -26.857071  ...  1751.875386   \n",
      "48950  178.44200    46.636821    57.528004     9.733384  ...  1923.466985   \n",
      "48951  284.00281    39.635630   -37.716024     2.639854  ...  2644.415578   \n",
      "48952  202.39628    45.517242    24.880028    17.567610  ...  1814.543975   \n",
      "48953  199.44444    41.021014   -38.453534   -12.226095  ...  1340.554454   \n",
      "48954  186.61832    40.812773   -39.638725   -27.610421  ...  2497.977034   \n",
      "48955  479.18975    25.961407  -247.238079   -46.754955  ...  2802.562707   \n",
      "48956  240.32608    21.030925  -183.753287   -92.747130  ...  2923.344067   \n",
      "48957  272.53506    21.250582  -193.799974   -80.554220  ...  2934.614717   \n",
      "48958  243.19955    19.845170  -162.868016   -59.478018  ...  3157.550665   \n",
      "48959  184.89424    14.938349  -139.812036  -156.021586  ...   905.326237   \n",
      "48960  338.78159    16.825319  -169.360123  -153.349486  ...  1401.535551   \n",
      "48961  202.78812    25.252178  -244.234754   -54.324061  ...  2732.224917   \n",
      "48962  213.62893    24.309946  -218.692844   -67.852278  ...  2593.389876   \n",
      "48963  368.61342    25.620144  -205.702299   -50.449608  ...  3691.297826   \n",
      "48964  212.89751    26.703377  -235.272609   -22.836605  ...  2582.770815   \n",
      "48965  216.34567    21.652529  -210.485647   -98.921464  ...  1664.786323   \n",
      "48966  300.19873    27.294008  -231.785095   -30.117977  ...  3180.302803   \n",
      "48967  386.50730    24.643914  -189.444975   -28.606059  ...  3744.941829   \n",
      "48968  394.73587    24.475746  -214.100556   -54.761819  ...  3813.819774   \n",
      "48969  462.96771    45.964888   106.716437   -72.673062  ...  3247.598229   \n",
      "48970  448.80934    47.219970   115.919570   -40.263762  ...  3493.030827   \n",
      "48971  443.79383    44.801296    65.479031   -48.016929  ...  1754.896798   \n",
      "...          ...          ...          ...          ...  ...          ...   \n",
      "59570  372.87138    42.865327   -40.682733   -56.220288  ...  3382.804475   \n",
      "59571  260.17914    45.477608    10.205029   -16.172366  ...  2982.926268   \n",
      "59572   90.30485    30.254267    70.887224    73.081333  ...  6609.531167   \n",
      "59573  230.19057    41.066202    30.971749   -21.895559  ...  6072.794225   \n",
      "59574  418.11546    41.289836    33.747737   -11.407270  ...  4588.779010   \n",
      "59575  299.07546    40.844058    29.042533    -4.168530  ...  5005.267821   \n",
      "59576  135.36608    33.500488    26.431921   -39.780423  ...  3453.187961   \n",
      "59577  244.94975    37.812867    34.290417    -9.124134  ...  5183.800088   \n",
      "59578  330.47465    43.483094    34.764794    -9.746754  ...  3909.421356   \n",
      "59579  724.94975    41.274070    34.778374     6.162417  ...  4931.188371   \n",
      "59580  291.68281    37.653787   -26.988636   -59.459208  ...  1934.853590   \n",
      "59581  347.37587    39.642051    -9.564100   -31.288402  ...  4161.853961   \n",
      "59582   51.43465    34.087321   -63.379054   -45.230603  ...  2297.364678   \n",
      "59583  248.86812    41.771400    10.892580    -5.713457  ...  5232.507373   \n",
      "59584  324.64934    43.677696     9.609806   -52.422915  ...  3040.714327   \n",
      "59585  336.45669    43.364247    16.221952   -25.597746  ...  8756.279586   \n",
      "59586  416.75710    42.906551   -13.428231    -7.614665  ...  2642.528941   \n",
      "59587  407.77098    42.990485    -1.702957   -32.457121  ...  5004.673199   \n",
      "59588  260.88444    47.254528    35.863937    -9.754201  ...  1678.530467   \n",
      "59589  204.95628    40.393983   -46.328756   -12.856760  ...  4283.042824   \n",
      "59590  204.59057    38.579161   -70.809438   -40.762798  ...  5086.812554   \n",
      "59591  366.65424    39.810385    -1.247941   -42.206783  ...  3259.714603   \n",
      "59592  225.90649    42.984383    61.237819    -4.459473  ...  3798.763731   \n",
      "59593  289.69751    44.194332   -32.580610   -32.565785  ...  2949.900859   \n",
      "59594  286.90240    40.075609     4.561701   -30.336935  ...  2958.079368   \n",
      "59595  348.96934    40.231725    46.282408   -13.655822  ...  4339.425990   \n",
      "59596  332.32934    43.813328     5.111750    -2.705070  ...  3759.486850   \n",
      "59597  182.04689    38.561170    21.603243   -43.954808  ...  4288.018243   \n",
      "59598  169.42975    41.280131     8.233834   -41.325696  ...  2846.537149   \n",
      "59599  653.13914    36.905053   -38.781680   -46.617109  ...  4674.278795   \n",
      "\n",
      "       var_timbre4  var_timbre5  var_timbre6  var_timbre7  var_timbre8  \\\n",
      "48942  1221.638146   501.717892  1091.743641   618.560018   402.236969   \n",
      "48943  1339.193474   889.918742  1148.824912   428.976969   306.187624   \n",
      "48944  3070.791615  1347.758671  1499.491510  1015.076345   897.411739   \n",
      "48945  1311.170435   809.621938   612.699944   492.734025   525.801667   \n",
      "48946  1536.674490  1167.316436   580.604008   498.168561   607.747214   \n",
      "48947  2652.946074  1193.215012  1440.767041   801.594088   894.983613   \n",
      "48948  2368.390791   760.020609  1127.502747   640.740103   951.981668   \n",
      "48949  1419.330450   929.904111   667.196887   713.451886   679.834467   \n",
      "48950  2389.602252   689.766378  1185.542375   677.856062   685.293097   \n",
      "48951  2275.405543  1209.712890   645.944754   613.899078   659.240221   \n",
      "48952  1762.921653   850.214406   966.321126   620.776094   574.899792   \n",
      "48953  1158.755317   737.384665   613.057752   572.560470   540.801287   \n",
      "48954  2106.688983   959.228970  1096.964992   609.528061   709.092373   \n",
      "48955  1415.285115  1343.656649   313.095184   409.300404   379.827609   \n",
      "48956  1820.837293   971.363729   634.471272   415.173431   481.799996   \n",
      "48957  1661.321965  1029.067435   473.101979   630.844444   548.830583   \n",
      "48958  1081.113286  1291.343258   462.269686   591.932428   251.827663   \n",
      "48959   985.747002   696.114865   193.215156   414.228332  1273.001170   \n",
      "48960  1039.654754   631.768924   185.142188   534.777859   983.953852   \n",
      "48961  1607.514880  1088.840336   498.819253   418.007762   547.023283   \n",
      "48962  1322.578920  1252.976866   375.710587   454.724611   627.058071   \n",
      "48963  1783.742923  1239.395811   591.148719   452.408210   375.503103   \n",
      "48964  1468.060618  1461.083786   369.054227   467.894665   443.809903   \n",
      "48965   733.909016   429.143658   268.946444   503.194760   317.185584   \n",
      "48966  1589.209078  2374.282214   739.956141   371.928906   483.195489   \n",
      "48967  2002.779188  1606.838248   719.420461   685.765990   266.176533   \n",
      "48968  1562.275016  1038.412298   553.483151   572.110514   280.127203   \n",
      "48969  3161.297500  1002.849758  2784.313676   688.236839  1226.917012   \n",
      "48970  2091.071166  1006.309600  1588.886059   740.004654   887.582960   \n",
      "48971  1470.117897  1026.633691  1776.550142   434.193942   525.249743   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "59570  4177.048486  1218.488578  2963.158268   639.252292   774.025840   \n",
      "59571  1605.925242  1318.469123  1155.088748  1266.676631   473.375730   \n",
      "59572  2773.177155  1025.613156  1181.814974  2161.792452   717.763487   \n",
      "59573  3602.927358  2223.908482  1470.669921  1237.412160   504.488955   \n",
      "59574  2537.124361  1426.548622  1071.310636  1175.591375   538.183802   \n",
      "59575  3351.592688  1797.448034  1232.758909  1513.067053   506.055987   \n",
      "59576  2194.771846  1607.906673  1435.020521  1185.068220  1213.292738   \n",
      "59577  2703.097285  1670.409989  1021.239750  1277.662024   646.000292   \n",
      "59578  2693.551221  1082.707332  1192.174606   916.684823   488.058608   \n",
      "59579  2488.478990  1791.148230  1086.141854  1605.271867   457.432995   \n",
      "59580  2496.493422  1090.410658  1095.056673  1070.759476   490.429245   \n",
      "59581  3553.719662  1423.875358  1921.913346  1080.366823   878.795238   \n",
      "59582  2848.931020   580.431445  1314.458041   726.351109   475.534395   \n",
      "59583  4082.307981  1595.928232  1614.356003  1646.481950   587.773628   \n",
      "59584  3060.578349  1378.172043  1278.758141  1119.751121   933.003189   \n",
      "59585  3056.589087  1698.198430   882.960450   855.182968   541.872523   \n",
      "59586  2102.871301  1124.627957  1511.526425  1698.083100   907.624053   \n",
      "59587  3069.957116  1812.817498  1220.897158  1129.074718   876.879876   \n",
      "59588  2259.869032   712.313947  1775.004669   672.330568  1030.779201   \n",
      "59589  2540.627228  2644.478413  1187.551030  1252.166806   695.638521   \n",
      "59590  2109.475504  1995.501723  1027.713521  1677.255470   848.610018   \n",
      "59591  4692.906026  1105.764463  1728.468341   987.181987  1436.369102   \n",
      "59592  1466.635246  1313.272631   752.043811  1377.236322   362.015723   \n",
      "59593  3445.059669  1127.182773  1241.365578  1333.745624  1037.144386   \n",
      "59594  3326.410135  1299.009504  1811.916095   854.911960   661.251020   \n",
      "59595  4081.017023  1248.530483  1655.677367  1000.603204   650.139870   \n",
      "59596  3703.892394  1413.063618  1375.104641   951.467238   621.927699   \n",
      "59597  3694.070826  1336.559501  1613.559675  1017.527699  1155.936991   \n",
      "59598  3655.514437  1811.926034  1705.581355  1024.020625  1052.533278   \n",
      "59599  3350.057925  1415.012485  1638.098332   815.354914  1790.130881   \n",
      "\n",
      "       var_timbre9  var_timbre10  var_timbre11  var_timbre12  \n",
      "48942   309.392602    233.206167    261.850703    240.834177  \n",
      "48943   368.973940    227.275123    261.643570    332.356536  \n",
      "48944   608.034880    549.493210    481.149049    442.663136  \n",
      "48945   585.984445    278.578591    250.545027    348.842236  \n",
      "48946   367.191519    403.532772    262.670577    272.634634  \n",
      "48947   476.321961    589.813962    405.382981    300.309110  \n",
      "48948   553.333874    559.235313    375.183605    316.228245  \n",
      "48949   412.356143    330.343611    257.591596    443.473980  \n",
      "48950   578.849227    438.426766    379.737622    409.140457  \n",
      "48951   495.361659    395.227021    330.374031    378.560555  \n",
      "48952   367.995356    484.996215    349.963023    303.594866  \n",
      "48953   343.048408    300.635006    169.514760    283.902171  \n",
      "48954   377.714441    430.448997    347.176523    533.212375  \n",
      "48955   316.302074    184.024179     75.750252    261.976365  \n",
      "48956   438.771230    188.733165     76.840088    295.477485  \n",
      "48957   380.989063    192.055375     81.859680    369.707920  \n",
      "48958   364.144807    195.049264     77.150978    358.435880  \n",
      "48959   339.204422    265.014245     61.104561    104.116751  \n",
      "48960   293.675641    297.769310     63.503684    134.910539  \n",
      "48961   331.205962    179.211505     74.982877    230.396446  \n",
      "48962   409.020292    202.055661     80.163358    229.398171  \n",
      "48963   429.364955    138.466419     76.920465    291.143583  \n",
      "48964   327.789155    198.329863     72.235352    311.034236  \n",
      "48965   302.073671    161.705008     55.488219    193.042122  \n",
      "48966   435.721560    163.644825     87.690354    252.577440  \n",
      "48967   524.289542    111.967735     73.833419    341.593418  \n",
      "48968   357.740290    124.699369     81.422678    371.648936  \n",
      "48969   446.262213    697.915840    850.451508    283.692335  \n",
      "48970   230.038286    540.536507    617.324972    226.067816  \n",
      "48971   177.347646    648.299954    435.778091    204.207204  \n",
      "...            ...           ...           ...           ...  \n",
      "59570   422.131872    617.396106    675.588643    263.530740  \n",
      "59571   799.541054    369.795254    411.218974    549.716312  \n",
      "59572   857.542525    647.484578    373.942823    547.900599  \n",
      "59573   349.256861    319.657347    565.783282    380.548608  \n",
      "59574   556.298293    373.685766    369.423306    542.453297  \n",
      "59575   557.159429    295.144030    486.630105    723.903997  \n",
      "59576   464.500859    614.507983    456.235398    447.772413  \n",
      "59577   459.120345    315.527215    362.441247    628.971359  \n",
      "59578   397.656996    335.921094    391.171410    449.465490  \n",
      "59579   640.814923    330.473528    410.875814    517.714660  \n",
      "59580   476.844816    301.328459    322.992640    604.265959  \n",
      "59581   785.997831    442.697408    505.862105    767.590862  \n",
      "59582   320.119999    492.963235    383.349800    312.589603  \n",
      "59583   559.488419    338.675524    572.860269    477.260112  \n",
      "59584   477.116751    627.901735    436.919522    594.714710  \n",
      "59585   455.890936    327.215682    435.912937    381.681691  \n",
      "59586   503.355419    434.923799    393.651343    396.008530  \n",
      "59587   487.667605    473.232900    531.444158    481.791847  \n",
      "59588   548.210792    543.245053    424.565553    268.325485  \n",
      "59589   428.649689    345.973107    323.380721    459.931348  \n",
      "59590   506.250871    490.391442    402.511335    335.370413  \n",
      "59591   405.367831    617.441452    669.821921    347.390881  \n",
      "59592   479.619521    251.784693    276.385797    344.769425  \n",
      "59593   444.940600    427.906384    486.911721    446.738452  \n",
      "59594   419.068479    418.439460    531.901731    407.200144  \n",
      "59595   487.150838    503.846148    641.508417    395.121718  \n",
      "59596   418.507034    409.707771    504.899788    350.913794  \n",
      "59597   422.885540    519.527734    538.895856    313.775934  \n",
      "59598   533.349475    591.853048    598.054091    443.893807  \n",
      "59599   562.270433    659.321422    531.850198    607.215961  \n",
      "\n",
      "[8350 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#Leer el archivo con los datos\n",
    "data = pd.read_csv('./data/msd_genre_dataset.csv')\n",
    "data=data.drop(['artist_name', 'track_id', 'title'], axis=1)\n",
    "data1=data.loc[data['genre'] == 'jazz and blues']\n",
    "data2=data.loc[data['genre'] == 'soul and reggae']\n",
    "data= pd.concat([data1, data2], axis= 0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se utilizan 600 datos para realizar las validaciones y evaluaciones del modelo respectivamente, entonces la confianza con la que el error estimado est√© m√°ximo a 0.1 de diferencia del error real es de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004258632642721\n"
     ]
    }
   ],
   "source": [
    "confianza=1-2*math.exp(-2*0.05**2*600)\n",
    "print(confianza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar esta confianza es del 90%. Lo cual significa que usar 600 datos es un buen estimativo para estar m√°ximo a 0.1 del error.\n",
    "Se parten los datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "3989 -0.007746  0.030671  0.001081  0.001351  0.000270  0.038641  0.004707   \n",
      "2962 -0.003219  0.024831  0.000703  0.000527  0.000176  0.142768  0.005611   \n",
      "6885 -0.003161  0.018672  0.001030  0.000000  0.000206  0.033097  0.007638   \n",
      "8003 -0.003776  0.038427  0.001272  0.000000  0.000000  0.062554  0.013290   \n",
      "2528 -0.002559  0.017013  0.000765  0.000000  0.000191  0.048355  0.007027   \n",
      "6877 -0.001435  0.018808  0.000564  0.000000  0.000141  0.024617  0.005608   \n",
      "7107 -0.001558  0.019494  0.000460  0.000805  0.000115  0.023422  0.004027   \n",
      "6453 -0.002304  0.016158  0.000799  0.001598  0.000200  0.051060  0.007661   \n",
      "5386 -0.002765  0.051769  0.001238  0.003096  0.000000  0.068269  0.013342   \n",
      "5329 -0.001658  0.032536  0.000746  0.001740  0.000249  0.045790  0.011759   \n",
      "2260 -0.003426  0.054033  0.001448  0.002533  0.000000  0.063492  0.015787   \n",
      "3913 -0.001795  0.018823  0.000576  0.000863  0.000144  0.034533  0.005333   \n",
      "2235 -0.004881  0.046409  0.001006  0.000671  0.000335  0.104029  0.012919   \n",
      "5583 -0.001483  0.033061  0.000897  0.000449  0.000224  0.047990  0.010135   \n",
      "2294 -0.005080  0.020556  0.001473  0.001473  0.000210  0.036935  0.006180   \n",
      "7256 -0.004689  0.031711  0.000764  0.000000  0.000191  0.042512  0.004945   \n",
      "2217 -0.002544  0.031588  0.000974  0.000487  0.000000  0.071066  0.009981   \n",
      "3251 -0.001465  0.011607  0.000173  0.000231  0.000000  0.006230  0.001276   \n",
      "8108 -0.005064  0.037978  0.001303  0.000000  0.000326  0.046173  0.012398   \n",
      "8305 -0.001170  0.022490  0.000765  0.001339  0.000191  0.053284  0.008708   \n",
      "5344 -0.001984  0.029389  0.001177  0.002590  0.000000  0.050927  0.010708   \n",
      "7729 -0.002604  0.018028  0.000955  0.001146  0.000000  0.044512  0.007109   \n",
      "8182 -0.002701  0.019032  0.000813  0.001830  0.000203  0.036798  0.007965   \n",
      "1870 -0.002428  0.019383  0.000172  0.000688  0.000172  0.016172  0.006408   \n",
      "4433 -0.003066  0.027497  0.001147  0.001147  0.000287  0.049352  0.011659   \n",
      "6800 -0.002626  0.034161  0.001242  0.001242  0.000000  0.086392  0.013518   \n",
      "2923 -0.004366  0.010872  0.000205  0.001024  0.000205  0.024091  0.006344   \n",
      "5974 -0.001419  0.011618  0.000214  0.002143  0.000214  0.045849  0.009995   \n",
      "3294 -0.002997  0.031386  0.001314  0.002103  0.000000  0.076057  0.010686   \n",
      "776  -0.001901  0.015398  0.000693  0.000000  0.000000  0.031610  0.005054   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "3219 -0.003837  0.022877  0.000915  0.002058  0.000000  0.078069  0.007633   \n",
      "659  -0.003089  0.017200  0.000952  0.001905  0.000238  0.093007  0.009548   \n",
      "797  -0.005838  0.034082  0.001040  0.002861  0.000000  0.098548  0.007395   \n",
      "755  -0.004137  0.086829  0.001899  0.001899  0.000475  0.096405  0.021887   \n",
      "8291 -0.001069  0.016898  0.000412  0.000515  0.000000  0.028709  0.003725   \n",
      "2496 -0.002423  0.012248  0.000960  0.000000  0.000192  0.082517  0.007448   \n",
      "7599 -0.002581  0.052733  0.001482  0.002223  0.000000  0.071668  0.017145   \n",
      "1871 -0.004678  0.010400  0.000172  0.001718  0.000172  0.024509  0.004563   \n",
      "2046 -0.002740  0.025645  0.000699  0.000873  0.000000  0.041440  0.006228   \n",
      "7877 -0.002480  0.015379  0.000884  0.000442  0.000000  0.020645  0.009460   \n",
      "4851 -0.001243  0.021122  0.000919  0.001148  0.000000  0.055362  0.010802   \n",
      "5072 -0.001949  0.016963  0.000754  0.001884  0.000000  0.051353  0.007286   \n",
      "2163 -0.002671  0.019083  0.000638  0.000479  0.000000  0.055853  0.005229   \n",
      "6036 -0.002086  0.027134  0.001085  0.000271  0.000000  0.019463  0.011924   \n",
      "6921 -0.002077  0.040138  0.001154  0.001385  0.000231  0.057480  0.010168   \n",
      "6216 -0.001837  0.010858  0.000549  0.000962  0.000137  0.032083  0.004972   \n",
      "537  -0.005239  0.012324  0.000784  0.000000  0.000157  0.115847  0.003018   \n",
      "2897 -0.004732  0.076072  0.001553  0.003106  0.000000  0.177823  0.016117   \n",
      "7768 -0.004035  0.050455  0.000308  0.000000  0.000308  0.047301  0.012615   \n",
      "2222 -0.002678  0.052305  0.000900  0.001575  0.000225  0.050481  0.008995   \n",
      "2599 -0.002260  0.041130  0.001030  0.000000  0.000258  0.082852  0.011049   \n",
      "705  -0.001330  0.015360  0.000138  0.000275  0.000138  0.031269  0.005475   \n",
      "3468 -0.003603  0.016162  0.000209  0.001462  0.000209  0.059561  0.006966   \n",
      "6744 -0.002612  0.023321  0.000716  0.001433  0.000239  0.043901  0.010046   \n",
      "5874 -0.002413  0.017520  0.000801  0.000200  0.000200  0.046889  0.007572   \n",
      "4373 -0.000852  0.023144  0.000657  0.001477  0.000000  0.039693  0.007113   \n",
      "7891 -0.000563  0.023459  0.000875  0.001313  0.000219  0.054848  0.010613   \n",
      "4859 -0.001391  0.022466  0.000927  0.000464  0.000232  0.041354  0.010944   \n",
      "3264 -0.003341  0.015346  0.001280  0.000256  0.000256  0.178529  0.010198   \n",
      "2732 -0.002324  0.020522  0.000444  0.001332  0.000148  0.035776  0.004983   \n",
      "\n",
      "            7         8         9   ...        20        21        22  \\\n",
      "3989  0.010022 -0.002148  0.005888  ...  0.298274  0.684928  0.071732   \n",
      "2962 -0.007898 -0.006308 -0.001352  ...  0.781093  0.223696  0.194095   \n",
      "6885 -0.025574 -0.004666 -0.003616  ...  0.646397  0.413180  0.345506   \n",
      "8003 -0.000099  0.010604  0.001427  ...  0.538966  0.516474  0.161159   \n",
      "2528 -0.004859 -0.001246  0.000264  ...  0.539636  0.458930  0.194068   \n",
      "6877 -0.005583 -0.003000  0.002117  ...  0.565515  0.559799  0.226142   \n",
      "7107 -0.002177 -0.006400  0.002587  ...  0.459863  0.565870  0.180007   \n",
      "6453 -0.002632 -0.005265 -0.002541  ...  0.574083  0.413954  0.262729   \n",
      "5386  0.006684 -0.004191 -0.002138  ...  0.574754  0.423985  0.266140   \n",
      "5329  0.001293 -0.000167  0.003393  ...  0.566066  0.454390  0.238108   \n",
      "2260  0.003312 -0.005459  0.001294  ...  0.608298  0.543006  0.098550   \n",
      "3913 -0.006893 -0.004254  0.005730  ...  0.569717  0.499500  0.235911   \n",
      "2235 -0.025487 -0.003886 -0.002971  ...  0.613311  0.456325  0.130930   \n",
      "5583 -0.004862 -0.004516  0.004046  ...  0.399404  0.651773  0.152247   \n",
      "2294 -0.042228 -0.005522 -0.004198  ...  0.628946  0.272118  0.401877   \n",
      "7256  0.000169 -0.000397  0.000218  ...  0.572128  0.534466  0.187170   \n",
      "2217 -0.032475  0.000291  0.001830  ...  0.478203  0.560247  0.182071   \n",
      "3251  0.010313 -0.001687 -0.001303  ...  0.251985  0.076120  0.114966   \n",
      "8108  0.002909 -0.007478  0.003438  ...  0.656640  0.428280  0.165804   \n",
      "8305  0.007178 -0.000367  0.006623  ...  0.519832  0.454344  0.215738   \n",
      "5344  0.001708  0.002573  0.002172  ...  0.589184  0.390649  0.248919   \n",
      "7729  0.003675 -0.002756  0.003043  ...  0.601733  0.487128  0.274735   \n",
      "8182  0.011691  0.003389  0.002056  ...  0.326117  0.212664  0.288846   \n",
      "1870 -0.009889  0.005416 -0.001815  ...  0.533513  0.467751  0.317256   \n",
      "4433  0.007763 -0.001597  0.001270  ...  0.473043  0.559553  0.182969   \n",
      "6800  0.010014 -0.006363  0.002631  ...  0.492844  0.576875  0.234285   \n",
      "2923 -0.037065 -0.000889 -0.001524  ...  0.505389  0.376197  0.135272   \n",
      "5974 -0.003254  0.001724  0.003944  ...  0.515385  0.561349  0.227371   \n",
      "3294 -0.014419  0.006892 -0.003082  ...  0.452324  0.245110  0.247736   \n",
      "776  -0.017414 -0.003543  0.002809  ...  0.553730  0.347228  0.120628   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "3219 -0.010835 -0.001457  0.000322  ...  0.550236  0.345290  0.116729   \n",
      "659  -0.006352 -0.005277 -0.000953  ...  0.608407  0.321559  0.110557   \n",
      "797  -0.013492  0.005276  0.000664  ...  0.628163  0.199598  0.120283   \n",
      "755   0.011155  0.006912 -0.002744  ...  0.416228  0.261076  0.190905   \n",
      "8291 -0.001048 -0.003941  0.001881  ...  0.400945  0.688765  0.209926   \n",
      "2496 -0.006652  0.001415 -0.001996  ...  0.620549  0.332257  0.205597   \n",
      "7599  0.015023 -0.001473  0.003059  ...  0.616379  0.461951  0.177501   \n",
      "1871 -0.023982  0.012994  0.000695  ...  0.854370  0.310271  0.131405   \n",
      "2046 -0.010365  0.003825  0.000990  ...  0.483341  0.177792  0.200822   \n",
      "7877  0.006575  0.003087  0.000589  ...  0.816389  0.317347  0.211936   \n",
      "4851  0.001341  0.004094  0.003774  ...  0.454058  0.424686  0.236519   \n",
      "5072  0.013380 -0.007537  0.005932  ...  0.394949  0.529826  0.228231   \n",
      "2163 -0.015598 -0.002929 -0.002697  ...  0.690101  0.337662  0.227064   \n",
      "6036  0.015919  0.007506  0.005796  ...  0.702126  0.331436  0.265056   \n",
      "6921  0.022504 -0.008319  0.000264  ...  0.635170  0.146617  0.226447   \n",
      "6216 -0.008280 -0.001184  0.002277  ...  0.548973  0.571836  0.126596   \n",
      "537   0.001753  0.017426  0.004027  ...  0.816383  0.293956  0.160759   \n",
      "2897 -0.000648 -0.005709 -0.001610  ...  0.390064  0.344196  0.209553   \n",
      "7768  0.006088  0.015266  0.002434  ...  0.369002  0.622643  0.149682   \n",
      "2222 -0.004919 -0.004101  0.000489  ...  0.187346  0.327697  0.098427   \n",
      "2599  0.011228  0.000421  0.000488  ...  0.479119  0.433181  0.239304   \n",
      "705  -0.005608 -0.009363  0.000811  ...  0.447800  0.255833  0.188260   \n",
      "3468 -0.023893  0.014665 -0.000527  ...  0.529424  0.193196  0.238326   \n",
      "6744  0.001351 -0.003252 -0.000751  ...  0.512147  0.526262  0.170499   \n",
      "5874  0.002165 -0.000160  0.004251  ...  0.576457  0.370178  0.187972   \n",
      "4373  0.002076 -0.004635  0.001287  ...  0.489124  0.619080  0.141886   \n",
      "7891  0.011584  0.002952  0.003511  ...  0.507493  0.523894  0.233682   \n",
      "4859  0.001346  0.003702  0.003555  ...  0.455082  0.527924  0.194322   \n",
      "3264  0.001611 -0.003351 -0.002719  ...  0.753622  0.343130  0.133451   \n",
      "2732 -0.017188 -0.000819 -0.001757  ...  0.415351  0.421024  0.208082   \n",
      "\n",
      "            23        24        25        26        27        28        29  \n",
      "3989  0.522036  0.090185  0.111077  0.053446  0.048557  0.054440  0.042623  \n",
      "2962  0.158919  0.177851  0.100343  0.143246  0.063641  0.043140  0.133338  \n",
      "6885  0.177808  0.165069  0.091586  0.131588  0.054434  0.051294  0.087175  \n",
      "8003  0.382181  0.208222  0.109047  0.085069  0.086306  0.103736  0.091738  \n",
      "2528  0.257482  0.182424  0.121488  0.082897  0.100163  0.067398  0.075442  \n",
      "6877  0.341207  0.093880  0.131419  0.111813  0.078416  0.069232  0.059291  \n",
      "7107  0.389241  0.086988  0.077722  0.069871  0.051146  0.082109  0.034790  \n",
      "6453  0.230883  0.165426  0.100152  0.080116  0.070653  0.071501  0.055209  \n",
      "5386  0.220177  0.213039  0.146408  0.279297  0.129735  0.092243  0.100031  \n",
      "5329  0.305213  0.218832  0.199851  0.158827  0.126428  0.142829  0.079358  \n",
      "2260  0.373849  0.156104  0.111479  0.054895  0.085110  0.111798  0.096387  \n",
      "3913  0.447858  0.142240  0.129931  0.038040  0.069807  0.107012  0.023198  \n",
      "2235  0.281637  0.193846  0.115136  0.107794  0.092291  0.068304  0.109992  \n",
      "5583  0.444619  0.164346  0.159641  0.108707  0.091687  0.109651  0.095331  \n",
      "2294  0.085251  0.355078  0.086171  0.205320  0.035945  0.042128  0.194126  \n",
      "7256  0.162598  0.154796  0.150625  0.113963  0.082303  0.054040  0.076937  \n",
      "2217  0.359389  0.145465  0.167250  0.088588  0.092468  0.115804  0.072585  \n",
      "3251  0.033420  0.033839  0.061017  0.020262  0.030464  0.012074  0.015685  \n",
      "8108  0.332642  0.079851  0.161936  0.078441  0.120165  0.063856  0.047019  \n",
      "8305  0.317508  0.129471  0.136136  0.118905  0.141429  0.094946  0.067826  \n",
      "5344  0.267959  0.187543  0.218744  0.120993  0.127476  0.108405  0.083945  \n",
      "7729  0.362538  0.211225  0.091796  0.136124  0.079556  0.101018  0.090972  \n",
      "8182  0.150724  0.147620  0.065862  0.093606  0.049934  0.046580  0.064824  \n",
      "1870  0.210168  0.182662  0.131232  0.077113  0.070705  0.069967  0.099022  \n",
      "4433  0.381879  0.191561  0.115581  0.105326  0.114645  0.084785  0.079532  \n",
      "6800  0.329555  0.281466  0.131020  0.128603  0.078152  0.080077  0.096555  \n",
      "2923  0.135799  0.072186  0.083414  0.043543  0.044703  0.030458  0.051219  \n",
      "5974  0.285562  0.213215  0.191807  0.093616  0.134092  0.101880  0.090054  \n",
      "3294  0.123651  0.194319  0.134591  0.119640  0.085595  0.052156  0.110009  \n",
      "776   0.177173  0.171139  0.128188  0.095581  0.069733  0.032344  0.052477  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "3219  0.279626  0.163469  0.117203  0.074008  0.077428  0.065240  0.069372  \n",
      "659   0.159561  0.099143  0.120213  0.053999  0.079935  0.053560  0.060937  \n",
      "797   0.109721  0.141125  0.086400  0.139475  0.048085  0.038412  0.099786  \n",
      "755   0.171775  0.139874  0.155758  0.089246  0.148561  0.057153  0.100530  \n",
      "8291  0.195028  0.136188  0.147996  0.043908  0.074457  0.070857  0.040997  \n",
      "2496  0.175663  0.113835  0.096272  0.078769  0.052771  0.062259  0.055567  \n",
      "7599  0.433180  0.147728  0.078599  0.061734  0.061610  0.163601  0.077458  \n",
      "1871  0.129468  0.122560  0.075173  0.038446  0.046722  0.045620  0.023558  \n",
      "2046  0.141637  0.094770  0.102510  0.066516  0.051999  0.044041  0.081457  \n",
      "7877  0.201727  0.161890  0.116521  0.093533  0.080241  0.056728  0.092114  \n",
      "4851  0.341669  0.228528  0.174541  0.079732  0.118658  0.101740  0.073731  \n",
      "5072  0.370789  0.140311  0.164537  0.125661  0.084183  0.080874  0.098443  \n",
      "2163  0.116329  0.286776  0.094225  0.106900  0.049659  0.048234  0.077554  \n",
      "6036  0.196665  0.198374  0.108453  0.094395  0.103238  0.060970  0.040753  \n",
      "6921  0.143562  0.135224  0.144895  0.104809  0.043108  0.047566  0.050454  \n",
      "6216  0.308258  0.089855  0.108993  0.065129  0.062149  0.103121  0.034806  \n",
      "537   0.058361  0.137967  0.047907  0.174628  0.026915  0.033030  0.098935  \n",
      "2897  0.310362  0.211760  0.122730  0.130722  0.103889  0.056174  0.084945  \n",
      "7768  0.298446  0.299954  0.114096  0.167501  0.073488  0.118526  0.099342  \n",
      "2222  0.277168  0.105935  0.141161  0.059447  0.099462  0.080503  0.042524  \n",
      "2599  0.248617  0.137544  0.108121  0.083303  0.109212  0.088406  0.079186  \n",
      "705   0.243769  0.157561  0.112321  0.072814  0.055537  0.070566  0.056930  \n",
      "3468  0.023198  0.204018  0.043751  0.118213  0.020951  0.023814  0.096638  \n",
      "6744  0.347685  0.071307  0.103267  0.064483  0.089246  0.105320  0.032215  \n",
      "5874  0.286667  0.163300  0.140209  0.088675  0.084798  0.086962  0.063078  \n",
      "4373  0.278914  0.110885  0.178036  0.091572  0.105519  0.099048  0.113597  \n",
      "7891  0.285686  0.188099  0.201533  0.128575  0.110636  0.078948  0.042942  \n",
      "4859  0.342070  0.216356  0.149293  0.073682  0.103103  0.086128  0.070212  \n",
      "3264  0.161743  0.077872  0.076566  0.047768  0.053535  0.056567  0.042830  \n",
      "2732  0.146757  0.104903  0.121298  0.119788  0.084094  0.061774  0.061911  \n",
      "\n",
      "[7750 rows x 30 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#La variable dependiente es la √∫ltima columna, las independientes son las anteriores.\n",
    "#Se normaliza las independientes y se convierte nuevamente en un DataFrame de Pandas\n",
    "x= pd.DataFrame.from_records(preprocessing.normalize(data.loc[:, data.columns != 'genre']))\n",
    "y= data.iloc[:,0:1]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"soul and reggae\", \"jazz and blues\"])\n",
    "y=pd.DataFrame(le.transform(y).astype(float).T)\n",
    "#Se divide el archivo para entrenamiento y test. Se reserven 10000 datos para test\n",
    "xTrainT, xTest, yTrainT, yTest = train_test_split(x, y, test_size = 600, random_state = 0)\n",
    "print(xTrainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "8064  1.0\n",
      "6747  1.0\n",
      "6382  1.0\n",
      "470   0.0\n",
      "5518  1.0\n",
      "2642  0.0\n",
      "7383  1.0\n",
      "4878  1.0\n",
      "2682  0.0\n",
      "751   0.0\n",
      "2210  0.0\n",
      "7052  1.0\n",
      "2010  0.0\n",
      "339   0.0\n",
      "5905  1.0\n",
      "7381  1.0\n",
      "1681  0.0\n",
      "7374  1.0\n",
      "1944  0.0\n",
      "3769  0.0\n",
      "8146  1.0\n",
      "1636  0.0\n",
      "6296  1.0\n",
      "4281  0.0\n",
      "369   0.0\n",
      "4500  1.0\n",
      "3256  0.0\n",
      "4635  1.0\n",
      "7322  1.0\n",
      "3564  0.0\n",
      "...   ...\n",
      "5704  1.0\n",
      "2176  0.0\n",
      "367   0.0\n",
      "4140  0.0\n",
      "5700  1.0\n",
      "2279  0.0\n",
      "7842  1.0\n",
      "1206  0.0\n",
      "1427  0.0\n",
      "4016  0.0\n",
      "770   0.0\n",
      "1615  0.0\n",
      "7840  1.0\n",
      "1349  0.0\n",
      "4787  1.0\n",
      "5116  1.0\n",
      "5670  1.0\n",
      "1320  0.0\n",
      "5624  1.0\n",
      "1316  0.0\n",
      "2722  0.0\n",
      "1433  0.0\n",
      "4652  1.0\n",
      "3919  0.0\n",
      "5981  1.0\n",
      "3469  0.0\n",
      "2636  0.0\n",
      "3181  0.0\n",
      "4668  1.0\n",
      "1763  0.0\n",
      "\n",
      "[7150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Se concatenan los datos de test\n",
    "newData= pd.concat([xTrainT,yTrainT], axis = 1)\n",
    "xTrain, xValidation, yTrain, yValidation = train_test_split(xTrainT, yTrainT, test_size = 600, random_state = 0)\n",
    "print(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funci√≥n para entrenar un √Årboles de decisi√≥n con Adaboost\n",
    "def trainTrees(min_samples_split,n_estimators):\n",
    "    clf = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=min_samples_split),n_estimators=n_estimators)\n",
    "    clf.fit(xTrain.values.tolist(), yTrain.values.tolist())   \n",
    "    return [clf,clf.score(xValidation,yValidation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En el primer arreglo se guardar√°n los errores y en el segundo los clasificadores entrenados\n",
    "errorsLayers=[]\n",
    "trees=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se iterar√°n por gammas y C's en un rango logar√≠tmico. Este rango fue hallado emp√≠ricamente\n",
    "min_samples_range = np.linspace(2,11,10).astype(int).tolist()\n",
    "estimators_range = np.linspace(70,170,10).astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Se itera por los gammas y los C's y se calcula el porcentaje de √©xito de cada svm con los datos de validaci√≥n\n",
    "for i in min_samples_range:\n",
    "    errorsTemp=[]\n",
    "    treesTemp=[]\n",
    "    for j in estimators_range:\n",
    "        tree=trainTrees(i,j)\n",
    "        treesTemp.append(tree[0])\n",
    "        errorsTemp.append(tree[1])\n",
    "    errorsLayers.append(errorsTemp)\n",
    "    trees.append(treesTemp)\n",
    "errorsLayers=np.array(errorsLayers)\n",
    "trees=np.array(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78       0.78166667 0.78       0.77833333 0.78333333 0.77166667\n",
      "  0.78833333 0.79       0.775      0.78      ]\n",
      " [0.87166667 0.87       0.875      0.87333333 0.86833333 0.86333333\n",
      "  0.88333333 0.87666667 0.87833333 0.875     ]\n",
      " [0.86       0.86166667 0.86666667 0.86666667 0.87666667 0.87166667\n",
      "  0.87       0.88333333 0.88166667 0.87166667]\n",
      " [0.865      0.86333333 0.86666667 0.88333333 0.87666667 0.87\n",
      "  0.86833333 0.87833333 0.86666667 0.875     ]\n",
      " [0.86833333 0.87166667 0.875      0.87833333 0.86333333 0.875\n",
      "  0.87       0.87666667 0.885      0.88666667]\n",
      " [0.85666667 0.875      0.87833333 0.86       0.87833333 0.87333333\n",
      "  0.875      0.88333333 0.87       0.88      ]\n",
      " [0.86666667 0.88166667 0.88333333 0.875      0.875      0.875\n",
      "  0.88333333 0.875      0.87333333 0.86833333]\n",
      " [0.86       0.89333333 0.87       0.88       0.86833333 0.88666667\n",
      "  0.87166667 0.86666667 0.88666667 0.87333333]\n",
      " [0.865      0.87       0.87166667 0.87166667 0.89       0.875\n",
      "  0.875      0.88333333 0.88       0.87      ]\n",
      " [0.875      0.86833333 0.875      0.87166667 0.87333333 0.87833333\n",
      "  0.89166667 0.87       0.87833333 0.87333333]]\n"
     ]
    }
   ],
   "source": [
    "print(errorsLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmo para encontrar los √≠ndices del elemento m√°s grande de un arreglo 2D, en caso de varias ocurrencias retorna la √∫ltima\n",
    "def findMaxIndexes(arr):\n",
    "    maxC=0\n",
    "    maxIndex=[-1,-1]\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr[0])):\n",
    "            if arr[i][j] is not None and arr[i][j]>=maxC:\n",
    "                maxIndex=[i,j]\n",
    "                maxC=arr[i][j]\n",
    "    return maxIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1\n",
      "0.8933333333333333\n",
      "9\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "#Se utiliza el algoritmo anterior para encontrar la red de mejor resultado\n",
    "[ind1,ind2]=findMaxIndexes(errorsLayers)\n",
    "print(ind1,ind2)\n",
    "print(errorsLayers[ind1][ind2])\n",
    "print(min_samples_range[ind1])\n",
    "print(estimators_range[ind2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n"
     ]
    }
   ],
   "source": [
    "#Se entrena un √°rbol de decisi√≥n ahora sin adaboost\n",
    "clf = DecisionTreeClassifier(min_samples_split=9)\n",
    "clf.fit(xTrain.values.tolist(), yTrain.values.tolist())   \n",
    "print(clf.score(xValidation,yValidation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.778333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.771667</td>\n",
       "      <td>0.788333</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.881667</td>\n",
       "      <td>0.871667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.886667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.881667</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.868333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se muestran los resultados en formato de tabla\n",
    "df=pd.DataFrame(errorsLayers)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el punto anterior se observa que un √°rbol de decisi√≥n con adaboost con m√≠nimo 9 muestras para subdividir un nodo y 81 estimadores de adaboost fue el que obtuvo el m√≠nimo error, esta tasa de √©xito se observa que corresponde a 0.893333. Esta tasa de √©xito es superior a la obtenida con la red neuronal en el reto 5 y ligeramente superior a la del svm en el reto 7. Esto prueba que incluso un modelo tan sencillo como es el de un √°rbol de decisi√≥n puede ver incrementado su tasa de √©xito significativamente con Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8566666666666667"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestTree= trees[ind1][ind2]\n",
    "#El svm de mejor resultado se entrena con los datos de entrenamiento totales\n",
    "bestTree.fit(xTrainT, yTrainT)\n",
    "#Se prueba con los datos de prueba\n",
    "bestTree.score(xTest,yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la tasa de √©xito de clasificaci√≥n es de 0.856666. Esta tasa de √©xito es menor que la tasa de √©xito con menos datos, esto puede deberse a que los datos finales de testing no encajaban con lo que el modelo se entren√≥. De acuerdo al c√°lculo anterior, se podr√≠a afirmar que con una confianza del 90% la tasa de √©xito m√≠nima es de 0.8466666666666667."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede concluir que un algoritmo de Boosting es √∫til para mejorar la tasa de clasificaci√≥n exitosa de un algoritmo tal como un √°rbol de decisi√≥n. Se puede observar por ejemplo que la tasa de √©xito del algoritmo con adaboost aumenta en m√°s de 0.1 respecto a tener el √°rbol de decisi√≥n solo. Es importante tener en cuenta que la pr√°cticidad de adaboost tambi√©n recide en que el √°rbol de decisi√≥n es r√°pido en su entrenamiento, por lo que el tiempo adicional que le toma a adaboost entrenar no es una complicaci√≥n significativa para el problema tratado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
